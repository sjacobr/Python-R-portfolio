{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "In this project we analyze posts in Hacker News, asking these questions:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "The data can be found here: [Hacker News Posts](https://www.kaggle.com/hacker-news/hacker-news-posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "from csv import reader\n",
    "opened_file = open(\"C:\\\\Users\\\\ASUS\\\\Downloads\\\\Hacker_News_Dataset.csv\", encoding = 'utf8')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we look at first 5 rows of our data\n",
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "# First row contains names of columns we don't want in data to analyze\n",
    "headers = hn[0]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16'],\n",
       " ['12578979',\n",
       "  'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake',\n",
       "  'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94',\n",
       "  '1',\n",
       "  '0',\n",
       "  'markgainor1',\n",
       "  '9/26/2016 3:14']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we get rid of the header but keep the rest of the data\n",
    "hn = hn[1:]\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12578908',\n",
       "  'Ask HN: What TLD do you use for local development?',\n",
       "  '',\n",
       "  '4',\n",
       "  '7',\n",
       "  'Sevrene',\n",
       "  '9/26/2016 2:53'],\n",
       " ['12578893',\n",
       "  'Muroc Maru',\n",
       "  'http://www.weirdca.com/location.php?location=511',\n",
       "  '1',\n",
       "  '0',\n",
       "  'x43b',\n",
       "  '9/26/2016 2:46'],\n",
       " ['12578879',\n",
       "  'Why companies make their products worse',\n",
       "  'https://www.1843magazine.com/ideas/the-daily/why-companies-make-their-products-worse',\n",
       "  '4',\n",
       "  '0',\n",
       "  'RachelF',\n",
       "  '9/26/2016 2:40'],\n",
       " ['12578866',\n",
       "  'Tuning AWS SQS Queues',\n",
       "  'http://blog.simontaranto.com/post/2016-09-25-tuning-aws-sqs.html/',\n",
       "  '3',\n",
       "  '0',\n",
       "  'srt32',\n",
       "  '9/26/2016 2:37'],\n",
       " ['12578857',\n",
       "  'The Promise of GitHub',\n",
       "  'http://constantbetasoftware.com/2016/09/26/github.html',\n",
       "  '2',\n",
       "  '0',\n",
       "  'ttam',\n",
       "  '9/26/2016 2:34']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glance at data\n",
    "hn[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Slicing\n",
    "\n",
    "Since we only want to analyze \"Show HN\" and \"Ask HN\" posts, we will now trim the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    lower_title = title.lower()\n",
    "    if lower_title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif lower_title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have 9139 'Ask HN' posts, 10,158 'Show HN' posts, and 273,822 other posts in our data set.\n",
    "\n",
    "Let's look at the first five lines of our Ask and Show datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53'], ['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17'], ['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57'], ['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48'], ['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']]\n",
      "\n",
      "[['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36'], ['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01'], ['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44'], ['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17'], ['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']]\n"
     ]
    }
   ],
   "source": [
    "# Ask\n",
    "print(ask_posts[:5])\n",
    "print('')\n",
    "# Show\n",
    "print(show_posts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "## Part One\n",
    "\n",
    "To see which posts get more user interaction, we will look at how many comments each type of posts get, on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393478498741656\n"
     ]
    }
   ],
   "source": [
    "# \"Ask HN\" posts\n",
    "total_ask_comments = 0\n",
    "row_num = 0\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "    row_num += 1\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / row_num\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "# \"Show HN\" posts\n",
    "total_show_comments = 0\n",
    "row_num = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    row_num += 1\n",
    "    \n",
    "avg_show_comments = total_show_comments / row_num\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, \"Ask HN\" posts generate far more comments, on average, than \"Show HN\" posts. This may be due to users wanting to help answer questions more so than showing off new projects.\n",
    "\n",
    "Since \"Ask HN\" posts are so popular, the remainder of this analysis will focus on \"Ask HN\" posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "\n",
    "Is there a time of day which generally leads to more popular posts?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9/26/2016 2:53', 7],\n",
       " ['9/26/2016 1:17', 3],\n",
       " ['9/25/2016 22:57', 0],\n",
       " ['9/25/2016 22:48', 3],\n",
       " ['9/25/2016 21:50', 2]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Library to help format time #\n",
    "import datetime as dt\n",
    "#-----------------------------#\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    new_list = []\n",
    "    time_col = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    new_list = [time_col, num_comments]\n",
    "    result_list.append(new_list)\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "result_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First part of each row (index 0) contains the date / time of each post, \n",
    "# the second part (index 1) contains the number of comments on given post\n",
    "\n",
    "for row in result_list:\n",
    "    date_and_time = row[0]\n",
    "    date_and_time = dt.datetime.strptime(date_and_time, \"%m/%d/%Y %H:%M\")\n",
    "    post_time = date_and_time.strftime(\"%H\")\n",
    "    if post_time not in counts_by_hour:\n",
    "        counts_by_hour[post_time] = 1\n",
    "        comments_by_hour[post_time] = int(row[1])\n",
    "    else:\n",
    "        counts_by_hour[post_time] += 1\n",
    "        comments_by_hour[post_time] += int(row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we created two dictionaries. \n",
    "\n",
    "The first, *counts_by_hour*, contains the number of ask posts created during each hour of the day.\n",
    "\n",
    "The second, *comments_by_hour*, contains the corresponding number of comments ask posts created at each hour received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make List of Average Number of Comments per Post in each Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11.137546468401487], ['01', 7.407801418439717], ['22', 8.804177545691905], ['21', 8.687258687258687], ['19', 7.163043478260869], ['17', 9.449744463373083], ['15', 28.676470588235293], ['14', 9.692007797270955], ['13', 16.31756756756757], ['11', 8.96474358974359], ['10', 10.684397163120567], ['09', 6.653153153153153], ['07', 7.013274336283186], ['03', 7.948339483394834], ['23', 6.696793002915452], ['20', 8.749019607843136], ['16', 7.713298791018998], ['08', 9.190661478599221], ['00', 7.5647840531561465], ['18', 7.94299674267101], ['12', 12.380116959064328], ['04', 9.7119341563786], ['06', 6.782051282051282], ['05', 8.794258373205741]]\n"
     ]
    }
   ],
   "source": [
    "avg_list = []\n",
    "for each in counts_by_hour:\n",
    "    avg_list.append([each, comments_by_hour[each] / counts_by_hour[each]])\n",
    "    \n",
    "print(avg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11.137546468401487, '02'],\n",
       " [7.407801418439717, '01'],\n",
       " [8.804177545691905, '22'],\n",
       " [8.687258687258687, '21'],\n",
       " [7.163043478260869, '19'],\n",
       " [9.449744463373083, '17'],\n",
       " [28.676470588235293, '15'],\n",
       " [9.692007797270955, '14'],\n",
       " [16.31756756756757, '13'],\n",
       " [8.96474358974359, '11'],\n",
       " [10.684397163120567, '10'],\n",
       " [6.653153153153153, '09'],\n",
       " [7.013274336283186, '07'],\n",
       " [7.948339483394834, '03'],\n",
       " [6.696793002915452, '23'],\n",
       " [8.749019607843136, '20'],\n",
       " [7.713298791018998, '16'],\n",
       " [9.190661478599221, '08'],\n",
       " [7.5647840531561465, '00'],\n",
       " [7.94299674267101, '18'],\n",
       " [12.380116959064328, '12'],\n",
       " [9.7119341563786, '04'],\n",
       " [6.782051282051282, '06'],\n",
       " [8.794258373205741, '05']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_list = []\n",
    "for val in avg_list:\n",
    "    swap_avg_list.append([val[1], val[0]])\n",
    "    \n",
    "swap_avg_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top avg. Comments per hour\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[28.676470588235293, '15'],\n",
       " [16.31756756756757, '13'],\n",
       " [12.380116959064328, '12'],\n",
       " [11.137546468401487, '02'],\n",
       " [10.684397163120567, '10'],\n",
       " [9.7119341563786, '04'],\n",
       " [9.692007797270955, '14'],\n",
       " [9.449744463373083, '17'],\n",
       " [9.190661478599221, '08'],\n",
       " [8.96474358974359, '11'],\n",
       " [8.804177545691905, '22'],\n",
       " [8.794258373205741, '05'],\n",
       " [8.749019607843136, '20'],\n",
       " [8.687258687258687, '21'],\n",
       " [7.948339483394834, '03'],\n",
       " [7.94299674267101, '18'],\n",
       " [7.713298791018998, '16'],\n",
       " [7.5647840531561465, '00'],\n",
       " [7.407801418439717, '01'],\n",
       " [7.163043478260869, '19'],\n",
       " [7.013274336283186, '07'],\n",
       " [6.782051282051282, '06'],\n",
       " [6.696793002915452, '23'],\n",
       " [6.653153153153153, '09']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_list, reverse = True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15: 28.68 average comments per post\n",
      "13: 16.32 average comments per post\n",
      "12: 12.38 average comments per post\n",
      "02: 11.14 average comments per post\n",
      "10: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "for val in sorted_swap[:5]:\n",
    "    my_hr = val[1]\n",
    "    my_hr = dt.datetime.strptime(my_hr, \"%H\")\n",
    "    post_time = my_hr.strftime(\"%H\")\n",
    "    print('{hr}: {num:.2f} average comments per post'.format(hr = post_time, num = val[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "\"Ask HN\" posts receive more traffic than \"Show HN\" posts.\n",
    "\n",
    "As we can see, the best times for user engagement on \"Ask HN\" posts are between 10 AM and 4 PM. These are common work hours. Perhaps people that are checking Hacker News are also taking a break at work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Research\n",
    "\n",
    "- Determine if show or ask posts receive more points on average.\n",
    "- Determine if posts created at a certain time are more likely to receive more points.\n",
    "- Compare your results to the average number of comments and points other posts receive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
